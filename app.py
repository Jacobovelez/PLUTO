import streamlit as st
import pandas as pd

from pluto_engine import (
    clean_projects_with_log,
    remove_outliers_iqr,
    kpis_global,
    kpis_by_complexity,
    plot_histograms,
    plot_boxplot_by_complexity,
    normality_test_by_complexity,
    plot_normality,
    fit_models_by_complexity,
    best_model_per_complexity,
    plot_models_overlay,
    completion_probability,
    get_best_model_for_complexity,
    evaluate_student_choice,
)

st.set_page_config(page_title="PLUTO ‚Äì Duration (mois)", layout="wide")

st.title("PLUTO ‚Äì Module formatif : analyse de la dur√©e (mois)")
st.caption("V2 : transparence nettoyage (NA + outliers) ‚Üí KPIs ‚Üí distributions.")

st.sidebar.header("1) Charger les donn√©es")
uploaded = st.sidebar.file_uploader("Fichier Excel (.xlsx) ou CSV", type=["xlsx", "xls", "csv"])

if uploaded is None:
    st.info("Charge un fichier pour commencer (ex: Base de donn√©es pluto.xlsx).")
    st.stop()

try:
    if uploaded.name.lower().endswith((".xlsx", ".xls")):
        raw = pd.read_excel(uploaded)
    else:
        raw = pd.read_csv(uploaded)
except Exception as e:
    st.error(f"Impossible de lire le fichier: {e}")
    st.stop()

st.subheader("Aper√ßu des donn√©es brutes")
st.dataframe(raw.head(20), use_container_width=True)
st.write(f"Dimensions: **{raw.shape[0]} lignes √ó {raw.shape[1]} colonnes**")

st.sidebar.header("2) Nettoyage / Outliers")
st.sidebar.markdown("**R√®gles appliqu√©es**")
st.sidebar.markdown("- Suppression des lignes avec donn√©es manquantes (NA) sur les colonnes cl√©s")
use_outliers = st.sidebar.checkbox("Supprimer les outliers (IQR par complexit√©)", value=True)
iqr_k = st.sidebar.slider("Facteur IQR (k)", min_value=1.0, max_value=3.0, value=1.5, step=0.1)
st.sidebar.info(
    "üßÆ **Comment fonctionne le facteur IQR (outliers)**\n\n"
    "On identifie les valeurs extr√™mes de *Duration* avec la r√®gle IQR, calcul√©e **par niveau de complexit√©**.\n\n"
    "**D√©finitions :**\n"
    "- Q1 = 25e percentile\n"
    "- Q3 = 75e percentile\n"
    "- IQR = Q3 ‚àí Q1\n\n"
    "**Bornes :**\n"
    "- Borne basse = Q1 ‚àí k √ó IQR\n"
    "- Borne haute = Q3 + k √ó IQR\n\n"
    "Une dur√©e est consid√©r√©e comme **extr√™me** si elle est en dehors de ces bornes.\n\n"
    "Le param√®tre **k** (par d√©faut 1.5) contr√¥le la s√©v√©rit√© du filtrage :\n"
    "- k plus petit ‚Üí plus d‚Äôoutliers supprim√©s\n"
    "- k plus grand ‚Üí filtrage plus tol√©rant\n\n"
    "Objectif : obtenir une base **repr√©sentative des projets standards**, sans supprimer des projets ‚Äúfaux‚Äù, "
    "mais en limitant l‚Äôinfluence des cas tr√®s atypiques sur les statistiques et les mod√®les."
)

clean_df, na_removed, na_summary = clean_projects_with_log(raw)

st.subheader("√âtape 1A ‚Äî Nettoyage : suppression des valeurs manquantes (NA)")
c1, c2, c3 = st.columns([1, 1, 1])
with c1:
    st.metric("Lignes initiales", int(na_summary["n_initial"]))
with c2:
    st.metric("Lignes supprim√©es (NA)", int(na_summary["n_removed_na"]))
with c3:
    st.metric("% supprim√© (NA)", f'{na_summary["pct_removed_na"]:.2f}%')

st.caption(
    "Les lignes avec NA sur les colonnes cl√©s ne permettent pas de calculer correctement "
    "les indicateurs, ni d‚Äôajuster un mod√®le pr√©dictif."
)

st.subheader("Liste des lignes supprim√©es (NA)")
if len(na_removed) == 0:
    st.write("Aucune ligne supprim√©e pour NA.")
else:
    st.dataframe(na_removed, use_container_width=True)

st.subheader("Donn√©es apr√®s nettoyage NA (base de travail)")
st.dataframe(clean_df.head(20), use_container_width=True)
st.write(f"Dimensions apr√®s NA: **{clean_df.shape[0]} lignes √ó {clean_df.shape[1]} colonnes**")

st.subheader("√âtape 1B ‚Äî Valeurs extr√™mes (outliers) sur Duration")
st.caption("Objectif : obtenir une base repr√©sentative des projets standards (sans cas extr√™mes rares).")

work_df = clean_df
out_info = None
out_removed = None

if use_outliers:
    work_df, out_info, out_removed = remove_outliers_iqr(work_df, var="duration_months", group="complexity", k=iqr_k)

    c1, c2, c3 = st.columns([1, 1, 1])
    with c1:
        st.metric("Lignes avant outliers", int(clean_df.shape[0]))
    with c2:
        st.metric("Outliers supprim√©s", int(out_info["outliers"].sum()) if out_info is not None else 0)
    with c3:
        pct = 100 * (out_info["outliers"].sum() / max(1, clean_df.shape[0])) if out_info is not None else 0
        st.metric("% supprim√© (outliers)", f"{pct:.2f}%")

    st.subheader("R√©sum√© outliers (bornes IQR par complexit√©)")
    st.dataframe(out_info, use_container_width=True)

    st.subheader("Liste des lignes supprim√©es (outliers)")
    if out_removed is None or len(out_removed) == 0:
        st.write("Aucun outlier supprim√©.")
    else:
        st.dataframe(out_removed, use_container_width=True)
else:
    st.info("Suppression d'outliers d√©sactiv√©e (tu peux l'activer dans la barre lat√©rale).")

st.divider()

col1, col2 = st.columns([1, 1])
with col1:
    st.subheader("KPIs globaux (Duration)")
    st.table(kpis_global(work_df, var="duration_months"))
with col2:
    st.subheader("KPIs par complexit√© (Duration)")
    st.dataframe(kpis_by_complexity(work_df, var="duration_months", group="complexity"), use_container_width=True)

st.subheader("Distributions (Duration) ‚Äì global & par complexit√©")
fig = plot_histograms(work_df, var="duration_months", group="complexity")
st.pyplot(fig, clear_figure=True)
st.success("Nettoyage termin√© ‚úÖ  Prochaine √©tape : √âtape 2 (analyse segment√©e) puis √âtape 3 (test de normalit√©).")

st.divider()
st.header("√âtape 2 ‚Äî Analyse segment√©e (par complexit√©)")

st.caption(
    "On compare les dur√©es par niveau de complexit√©. "
    "Si les distributions diff√®rent, on justifie une mod√©lisation s√©par√©e par complexit√©."
)

fig_box = plot_boxplot_by_complexity(work_df, var="duration_months", group="complexity")
st.pyplot(fig_box, clear_figure=True)




st.divider()
st.header("√âtape 3 ‚Äî Test de normalit√© (par complexit√©)")

st.caption(
    "On teste si la dur√©e suit une distribution normale pour chaque niveau de complexit√©. "
    "Ce test sert √† orienter le choix du mod√®le statistique."
)

norm_table = normality_test_by_complexity(
    work_df,
    var="duration_months",
    group="complexity"
)

st.subheader("R√©sultats du test de normalit√© (Shapiro‚ÄìWilk)")
st.dataframe(norm_table, use_container_width=True)

st.subheader("Visualisation : histogramme + loi normale")
fig_norm = plot_normality(
    work_df,
    var="duration_months",
    group="complexity"
)
st.pyplot(fig_norm, clear_figure=True)

st.divider()
st.header("√âtape 3.5 ‚Äî Choix de la distribution (par complexit√©)")

st.caption(
    "Avant que PLUTO r√©v√®le la meilleure distribution, tu choisis toi-m√™me une loi pour chaque complexit√©. "
    "Ensuite PLUTO compare ton choix au meilleur mod√®le selon le crit√®re BIC et explique pourquoi."
)

# On calcule les ajustements une seule fois (on les r√©utilise ensuite pour l‚Äô√©tape 4)
fit_tbl = fit_models_by_complexity(work_df, var="duration_months", group="complexity")

# PLUTO : meilleur mod√®le par complexit√© selon BIC
best_bic = best_model_per_complexity(fit_tbl, criterion="bic")

models_list = ["normal", "lognorm", "gamma", "weibull", "expon"]
complexities = sorted(work_df["complexity"].unique().tolist())

st.subheader("Choix √©tudiant")
student_choices = {}

for comp in complexities:
    # choix de l'√©tudiant
    student_choices[comp] = st.selectbox(
        f"Choisis une distribution pour la complexit√© : {comp}",
        models_list,
        key=f"choice_{comp}"
    )

st.subheader("Feedback PLUTO (comparaison BIC)")
for comp in complexities:
    chosen = student_choices[comp]
    res = evaluate_student_choice(fit_tbl, complexity_value=comp, chosen_model=chosen, criterion="bic")

    st.markdown(f"### Complexit√© : `{comp}`")
    st.write(f"**Ton choix :** {chosen}")
    st.write(f"**PLUTO (meilleur BIC) :** {res.get('best_model', '‚Äî')}")
    st.write(f"**Verdict :** {res['status']}")
    st.info(res["message"])
    if "extra" in res:
        st.caption(res["extra"])

    # optionnel : afficher le graphique des mod√®les pour aider visuellement
    with st.expander("Voir les distributions ajust√©es (histogramme + mod√®les)"):
        fig_overlay = plot_models_overlay(
            work_df,
            var="duration_months",
            group="complexity",
            fit_table=fit_tbl,
            complexity_value=comp
        )
        if fig_overlay is not None:
            st.pyplot(fig_overlay, clear_figure=True)
        else:
            st.warning("Pas assez de donn√©es pour tracer les mod√®les.")

st.divider()
st.header("√âtape 4 ‚Äî S√©lection du mod√®le statistique optimal (par complexit√©)")

st.caption(
    "On teste plusieurs mod√®les statistiques pour la dur√©e (Gaussian, Log-Normal, Gamma, Weibull, Exponential). "
    "On compare leurs performances avec AIC/BIC et on s√©lectionne le meilleur mod√®le par complexit√©."
)


st.subheader("Tableau comparatif des mod√®les (AIC / BIC)")
st.dataframe(fit_tbl.sort_values(["complexity", "aic"]), use_container_width=True)

best_bic = best_model_per_complexity(fit_tbl, criterion="bic")
st.subheader("Meilleur mod√®le par complexit√© (crit√®re BIC)")
st.dataframe(best_bic[["complexity", "model", "n", "aic", "bic"]], use_container_width=True)


st.subheader("Visualisation : histogramme + mod√®les ajust√©s (par complexit√©)")
complexities = sorted(work_df["complexity"].unique().tolist())
selected_comp = st.selectbox("Choisir une complexit√©", complexities)

fig_overlay = plot_models_overlay(
    work_df,
    var="duration_months",
    group="complexity",
    fit_table=fit_tbl,
    complexity_value=selected_comp
)
if fig_overlay is not None:
    st.pyplot(fig_overlay, clear_figure=True)
else:
    st.warning("Pas assez de donn√©es pour tracer les mod√®les.")

st.divider()
st.header("√âtape 5 ‚Äî Prediction test (par complexit√©)")

st.caption(
    "On choisit une complexit√© et une dur√©e cible. "
    "On calcule la probabilit√© de terminer avant la cible selon : "
    "1) un mod√®le Gaussien, 2) le mod√®le optimal s√©lectionn√© (AIC)."
)

# On r√©utilise fit_tbl et best_aic d√©j√† calcul√©s √† l'√©tape 4
complexities = sorted(work_df["complexity"].unique().tolist())
comp_pred = st.selectbox("Complexit√© du projet", complexities, key="comp_pred")

target = st.number_input("Dur√©e cible (mois)", min_value=1.0, value=24.0, step=1.0)

# --- r√©cup√©rer param√®tres du mod√®le optimal
best_model, best_params = get_best_model_for_complexity(best_bic, comp_pred)

# --- r√©cup√©rer aussi params du normal (depuis fit_tbl)
row_norm = fit_tbl[(fit_tbl["complexity"] == comp_pred) & (fit_tbl["model"] == "normal")]
norm_params = None if row_norm.empty else row_norm.iloc[0]["params"]

p_best = completion_probability(best_model, best_params, target)
p_norm = completion_probability("normal", norm_params, target)

c1, c2 = st.columns(2)
with c1:
    st.subheader("Mod√®le Gaussien")
    if p_norm is None:
        st.warning("Impossible de calculer la probabilit√© (normal).")
    else:
        st.metric("P(Duration ‚â§ cible)", f"{100*p_norm:.1f}%")

with c2:
    st.subheader("Mod√®le optimal (AIC)")
    st.write(f"Mod√®le s√©lectionn√© : **{best_model}**")
    if p_best is None:
        st.warning("Impossible de calculer la probabilit√© (mod√®le optimal).")
    else:
        st.metric("P(Duration ‚â§ cible)", f"{100*p_best:.1f}%")

# message p√©dagogique
if (p_norm is not None) and (p_best is not None):
    delta = (p_best - p_norm) * 100
    st.info(
        f"Diff√©rence (optimal - gaussien) : **{delta:.1f} points**. "
        "Si la distribution n‚Äôest pas normale, le mod√®le optimal donne souvent une estimation plus r√©aliste."
    )
